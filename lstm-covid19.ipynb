{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Qjor0jHDihhG",
    "outputId": "014d27b3-6bcb-494b-ed09-4f238b1516a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nova\\AppData\\Local\\Temp\\ipykernel_32740\\3606609494.py:14: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv('./train.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Population    Weight  TargetValue\n",
      "Date                                         \n",
      "2020-01-23    27657145  0.058359            0\n",
      "2020-01-24    27657145  0.058359            0\n",
      "2020-01-25    27657145  0.058359            0\n",
      "2020-01-26    27657145  0.058359            0\n",
      "2020-01-27    27657145  0.058359            0\n",
      "...                ...       ...          ...\n",
      "2020-06-06    14240168  0.060711           14\n",
      "2020-06-07    14240168  0.060711            3\n",
      "2020-06-08    14240168  0.060711            5\n",
      "2020-06-09    14240168  0.060711           27\n",
      "2020-06-10    14240168  0.060711            6\n",
      "\n",
      "[484820 rows x 3 columns]\n",
      "(484820, 3)\n",
      "[[0.01981486 0.05835874 0.        ]\n",
      " [0.01981486 0.05835874 0.        ]\n",
      " [0.01981486 0.05835874 0.        ]\n",
      " ...\n",
      " [0.01020229 0.06071064 0.00013826]\n",
      " [0.01020229 0.06071064 0.00074662]\n",
      " [0.01020229 0.06071064 0.00016592]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler, LabelEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras import metrics\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "####atom://teletype/portal/3f155216-29d7-4279-882f-d6aec0f4c85b\n",
    "\n",
    "df_train = pd.read_csv('./train.csv')\n",
    "df_test = pd.read_csv('./test.csv')\n",
    "\n",
    "train_data = df_train.drop(\n",
    "    ['Id', 'County', 'Province_State', 'Country_Region'], axis=1)\n",
    "#test_data = df_test.drop(\n",
    "#    ['County', 'Province_State', 'Country_Region'], axis=1)\n",
    "train_data.set_index('Date', inplace=True)\n",
    "#test_data.set_index('Date', inplace=True)\n",
    "\n",
    "train_confirm = train_data[train_data['Target'] == 'ConfirmedCases']\n",
    "train_confirm = train_confirm.drop(['Target'], axis = 1)\n",
    "train_confirm['TargetValue'] = np.where(train_confirm['TargetValue'] <=0, 0, train_confirm['TargetValue'])\n",
    "print(train_confirm)\n",
    "\n",
    "X = train_confirm.iloc[:, 0: 4].to_numpy()\n",
    "Y = train_data.iloc[:, 4: 5].to_numpy()\n",
    "\n",
    "# MinMaxScaling线性函数归一化\n",
    "\n",
    "sc_pop = MinMaxScaler(feature_range=(0, 1))\n",
    "sc_tg = MinMaxScaler(feature_range=(0, 1))\n",
    "X[:, 0:1] = sc_pop.fit_transform(X[:, 0:1])\n",
    "X[:, 2:3] = sc_tg.fit_transform(X[:, 2:3])\n",
    "\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484812\n",
      "(4489, 108, 3)\n"
     ]
    }
   ],
   "source": [
    "#为了reshape舍弃部分数据，下同\n",
    "X = X[:484820//(108)*108]\n",
    "X = X.reshape(-1,108,3)\n",
    "print(X.shape)\n",
    "#print(df_train.dtypes)\n",
    "#print(X)\n",
    "\n",
    "def multivariate_data(dataset, target, start_index, end_index, time_step) :\n",
    "\tdata=list()\n",
    "\tlabel =list()\n",
    "\n",
    "\tstart_index = start_index + time_step\n",
    "\tfor i in range(start_index, end_index) :\n",
    "\t\tindices = range(i-time_step, i)\n",
    "\t\tdata.append(dataset[indices])\n",
    "\t\tlabel.append(target[i])\n",
    "\n",
    "\treturn np.array(data), np.array(label)\n",
    "\n",
    "time_step = 40\n",
    "partition = 108-4-time_step\n",
    "X_train, Y_train = multivariate_data(X[0,:,:], X[0,:,2], 0, 108, time_step)\n",
    "\n",
    "for i in range(1,3463) :\n",
    "\tX_dummy, Y_dummy = multivariate_data(X[i,:,:], X[i,:,2], 0, 108, time_step)\n",
    "\tX_train = np.concatenate((X_train, X_dummy), axis = 0)\n",
    "\tY_train = np.concatenate((Y_train, Y_dummy), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hwu7cQK8m-gM",
    "outputId": "3f789cfc-6aff-4eba-a007-516250b0e5ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "7359/7359 [==============================] - 250s 33ms/step - loss: 7.4946e-05\n",
      "Epoch 2/7\n",
      "7359/7359 [==============================] - 214s 29ms/step - loss: 5.5971e-05\n",
      "Epoch 3/7\n",
      "7359/7359 [==============================] - 214s 29ms/step - loss: 5.0207e-05\n",
      "Epoch 4/7\n",
      "7359/7359 [==============================] - 214s 29ms/step - loss: 4.5237e-05\n",
      "Epoch 5/7\n",
      "7359/7359 [==============================] - 213s 29ms/step - loss: 4.1531e-05\n",
      "Epoch 6/7\n",
      "7359/7359 [==============================] - 214s 29ms/step - loss: 3.8349e-05\n",
      "Epoch 7/7\n",
      "7359/7359 [==============================] - 214s 29ms/step - loss: 4.0785e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21f0facd550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = Sequential()\n",
    "\n",
    "regressor.add(LSTM(units = 16, return_sequences = True, input_shape = (X_train.shape[1], 3)))\n",
    "regressor.add(Dropout(0.3))\n",
    "regressor.add(LSTM(units = 16, return_sequences = True))\n",
    "regressor.add(Dropout(0.3))\n",
    "regressor.add(LSTM(units = 16, return_sequences = True))\n",
    "regressor.add(Dropout(0.3))\n",
    "regressor.add(LSTM(units = 16))\n",
    "regressor.add(Dropout(0.3))\n",
    "regressor.add(Dense(units = 1))\n",
    "regressor.compile(optimizer = 'RMSprop', loss = 'mean_squared_error')\n",
    "regressor.fit(X_train, Y_train, epochs = 7, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "iI9K_pj_uZgh",
    "outputId": "7b85e40d-340e-4378-ab8c-d75811c8086e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 40, 3)\n",
      "4870/4870 [==============================] - 36s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "test_data = df_test.drop(\n",
    "    ['ForecastId','County', 'Province_State', 'Country_Region'], axis=1)\n",
    "test_data.set_index('Date', inplace=True)\n",
    "test_confirm = test_data[test_data['Target'] == 'ConfirmedCases']\n",
    "test_confirm = test_confirm.drop(['Target'], axis = 1)\n",
    "\n",
    "x_test = test_confirm.iloc[:, 0: 4].values\n",
    "(a,b) = x_test.shape\n",
    "x_test[:, 0:1] = sc_pop.fit_transform(x_test[:, 0:1])\n",
    "\n",
    "X_modify = np.zeros(shape = (a,b+1))\n",
    "X_modify[:,:-1] = x_test\n",
    "X_modify = X_modify.reshape(-1,45,3)\n",
    "\n",
    "X_t1 = X_modify[0,:,:]\n",
    "X_t2 = X[0,:,:]\n",
    "X_t3 = np.concatenate((X_t2,X_t1), axis = 0)\n",
    "st_index = 107 - time_step\n",
    "X_t3 = X_t3[st_index:160,:]\n",
    "X_test1, Y_d1 = multivariate_data(X_t3, X_t3[:,2], 0, time_step + 45, time_step)\n",
    "print(X_test1.shape)\n",
    "\n",
    "for i in range (1,3463) :\n",
    "\tx_t1 = X_modify[i,:,:]\n",
    "\tX_t2 = X[i,:,:]\n",
    "\tX_t3 = np.concatenate((X_t2,X_t1), axis = 0)\n",
    "\tX_t3 = X_t3[st_index:160,:]\n",
    "\tX_test_dummy, Y_d1 = multivariate_data(X_t3, X_t3[:,2], 0, time_step + 45, time_step)\n",
    "\tX_test1 = np.concatenate((X_test1, X_test_dummy), axis =0)\n",
    "\n",
    "predicted_test = regressor.predict(X_test1)\n",
    "predicted_test = sc_tg.inverse_transform(predicted_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gpcJSpuQONhX",
    "outputId": "6f795a07-b81f-47d4-ea77-7f7ad2e77ba4"
   },
   "outputs": [],
   "source": [
    "pred_test_flat = predicted_test.flatten()\n",
    "pred_test_flat = pred_test_flat.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Jaibu4K6Fsa2",
    "outputId": "b67c5eba-1936-4e40-e1bb-ad3f8f876cde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155835,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rXqV91fYDInj",
    "outputId": "4d5aa824-f690-46a1-9526-a449a9934c22"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pred_test_flat)\n",
    "my_list = [*range(2,935011,6)]\n",
    "df['Id_1'] = my_list\n",
    "df.rename(columns = {0 : 'Predicted_Results'}, inplace = True)\n",
    "df['Predicted_Results'] = np.where(df['Predicted_Results'] <0, 0, df['Predicted_Results'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1a4tdGPjJdr0",
    "outputId": "3c32c811-e294-414c-ef04-bbfef53335de"
   },
   "outputs": [],
   "source": [
    "s1 = df['Predicted_Results']\n",
    "l1 = s1.tolist()\n",
    "l2 = [i for i in l1]\n",
    "l1 = [i for i in l2]\n",
    "l2 = [round(i) for i in l1]\n",
    "df2 = pd.DataFrame(l2)\n",
    "\n",
    "my_list = [*range(3,935011,6)]\n",
    "df2['Id_1'] = my_list\n",
    "df2.rename(columns = {0 : 'Predicted_Results'}, inplace = True)\n",
    "\n",
    "s1 = df['Predicted_Results']\n",
    "l1 = s1.tolist()\n",
    "l2 = [i for i in l1]\n",
    "l1 = [i for i in l2]\n",
    "l2 = [round(i) for i in l1]\n",
    "df3 = pd.DataFrame(l2)\n",
    "\n",
    "my_list = [*range(1,935011,6)]\n",
    "df3['Id_1'] = my_list\n",
    "df3.rename(columns = {0 : 'Predicted_Results'}, inplace = True)\n",
    "\n",
    "result_confirmed_cases = pd.concat([df, df2, df3])\n",
    "result_confirmed_cases.sort_values(by = ['Id_1'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZPx5IlOwO3V2",
    "outputId": "179fc672-c5e1-479a-c853-1e17f53cb0b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4489, 108, 3)\n"
     ]
    }
   ],
   "source": [
    "train_confirm1 = train_data[train_data['Target'] == 'Fatalities']\n",
    "train_confirm1 = train_confirm1.drop(['Target'], axis = 1)\n",
    "train_confirm1['TargetValue'] = np.where(train_confirm1['TargetValue'] <=0, 0, train_confirm1['TargetValue'])\n",
    "#print(train_confirm)\n",
    "\n",
    "X1 = train_confirm1.iloc[:, 0: 4].to_numpy()\n",
    "\n",
    "# MinMaxScaling\n",
    "\n",
    "X1[:, 0:1] = sc_pop.fit_transform(X1[:, 0:1])\n",
    "X1[:, 2:3] = sc_tg.fit_transform(X1[:, 2:3])\n",
    "\n",
    "X1 = X1[:484820//(108)*108]\n",
    "X1 = X1.reshape(-1,108,3)\n",
    "print(X1.shape)\n",
    "#print(df_train.dtypes)\n",
    "#print(X)\n",
    "\n",
    "def multivariate_data(dataset, target, start_index, end_index, time_step) :\n",
    "\tdata=list()\n",
    "\tlabel =list()\n",
    "\n",
    "\tstart_index = start_index + time_step\n",
    "\tfor i in range(start_index, end_index) :\n",
    "\t\tindices = range(i-time_step, i)\n",
    "\t\tdata.append(dataset[indices])\n",
    "\t\tlabel.append(target[i])\n",
    "\n",
    "\treturn np.array(data), np.array(label)\n",
    "\n",
    "X_train1, Y_train1 = multivariate_data(X1[0,:,:], X1[0,:,2], 0, 108, time_step)\n",
    "\n",
    "for i in range(1,3463) :\n",
    "\tX_dummy, Y_dummy = multivariate_data(X1[i,:,:], X1[i,:,2], 0, 108, time_step)\n",
    "\tX_train1 = np.concatenate((X_train1, X_dummy), axis = 0)\n",
    "\tY_train1 = np.concatenate((Y_train1, Y_dummy), axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-gCVzZrVQPbG",
    "outputId": "0c0fb13a-02e2-4d89-8081-0feb18ba5765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "7359/7359 [==============================] - 215s 29ms/step - loss: 3.0435e-05\n",
      "Epoch 2/7\n",
      "7359/7359 [==============================] - 211s 29ms/step - loss: 2.2581e-05\n",
      "Epoch 3/7\n",
      "7359/7359 [==============================] - 210s 29ms/step - loss: 2.1310e-05\n",
      "Epoch 4/7\n",
      "7359/7359 [==============================] - 209s 28ms/step - loss: 2.0646e-05\n",
      "Epoch 5/7\n",
      "7359/7359 [==============================] - 209s 28ms/step - loss: 1.9958e-05\n",
      "Epoch 6/7\n",
      "7359/7359 [==============================] - 210s 29ms/step - loss: 1.9385e-05\n",
      "Epoch 7/7\n",
      "7359/7359 [==============================] - 211s 29ms/step - loss: 1.8988e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21f1d970e50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor1 = Sequential()\n",
    "\n",
    "regressor1.add(LSTM(units = 16, return_sequences = True, input_shape = (X_train1.shape[1], 3)))\n",
    "regressor1.add(Dropout(0.3))\n",
    "regressor1.add(LSTM(units = 16, return_sequences = True))\n",
    "regressor1.add(Dropout(0.3))\n",
    "regressor1.add(LSTM(units = 16, return_sequences = True))\n",
    "regressor1.add(Dropout(0.3))\n",
    "regressor1.add(LSTM(units = 16))\n",
    "regressor1.add(Dropout(0.3))\n",
    "regressor1.add(Dense(units = 1))\n",
    "regressor1.compile(optimizer = 'RMSprop', loss = 'mean_squared_error')\n",
    "regressor1.fit(X_train1, Y_train1, epochs = 7, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kbO5iDXgQdaI",
    "outputId": "4e7ea164-b52b-4a5b-dd27-95437acb6d5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4870/4870 [==============================] - 33s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "test_data = df_test.drop(\n",
    "    ['ForecastId','County', 'Province_State', 'Country_Region'], axis=1)\n",
    "test_data.set_index('Date', inplace=True)\n",
    "test_confirm = test_data[test_data['Target'] == 'Fatalities']\n",
    "test_confirm = test_confirm.drop(['Target'], axis = 1)\n",
    "\n",
    "x_test = test_confirm.iloc[:, 0: 4].values\n",
    "(a,b) = x_test.shape\n",
    "x_test[:, 0:1] = sc_pop.fit_transform(x_test[:, 0:1])\n",
    "\n",
    "X_modify = np.zeros(shape = (a,b+1))\n",
    "X_modify[:,:-1] = x_test\n",
    "X_modify = X_modify.reshape(-1,45,3)\n",
    "\n",
    "X_t1 = X_modify[0,:,:]\n",
    "X_t2 = X[0,:,:]\n",
    "X_t3 = np.concatenate((X_t2,X_t1), axis = 0)\n",
    "st_index = 107 - time_step\n",
    "X_t3 = X_t3[st_index:160,:]\n",
    "X_test1, Y_d1 = multivariate_data(X_t3, X_t3[:,2], 0, time_step + 45, time_step)\n",
    "\n",
    "for i in range (1,3463) :\n",
    "\tx_t1 = X_modify[i,:,:]\n",
    "\tX_t2 = X[i,:,:]\n",
    "\tX_t3 = np.concatenate((X_t2,X_t1), axis = 0)\n",
    "\tX_t3 = X_t3[st_index:160,:]\n",
    "\tX_test_dummy, Y_d1 = multivariate_data(X_t3, X_t3[:,2], 0, time_step + 45, time_step)\n",
    "\tX_test1 = np.concatenate((X_test1, X_test_dummy), axis =0)\n",
    "\n",
    "predicted_test = regressor1.predict(X_test1)\n",
    "predicted_test = sc_tg.inverse_transform(predicted_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vsLtn9BZRWHt",
    "outputId": "7915b827-ebb3-43e5-b959-a1a252971860"
   },
   "outputs": [],
   "source": [
    "pred_test_flat = predicted_test.flatten()\n",
    "pred_test_flat = pred_test_flat.astype(int)\n",
    "df4 = pd.DataFrame(pred_test_flat)\n",
    "my_list = [*range(5,935011,6)]\n",
    "df4['Id_1'] = my_list\n",
    "df4.rename(columns = {0 : 'Predicted_Results'}, inplace = True)\n",
    "df4['Predicted_Results'] = np.where(df4['Predicted_Results'] <0, 0, df4['Predicted_Results'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "0C5a7e69R-w1",
    "outputId": "243dfb18-e455-416e-c303-e06aa9cc2ad8"
   },
   "outputs": [],
   "source": [
    "s1 = df4['Predicted_Results']\n",
    "l1 = s1.tolist()\n",
    "l2 = [i for i in l1]\n",
    "l1 = [i for i in l2]\n",
    "l2 = [round(i) for i in l1]\n",
    "df5 = pd.DataFrame(l2)\n",
    "\n",
    "my_list = [*range(6,935011,6)]\n",
    "df5['Id_1'] = my_list\n",
    "df5.rename(columns = {0 : 'Predicted_Results'}, inplace = True)\n",
    "\n",
    "s1 = df4['Predicted_Results']\n",
    "l1 = s1.tolist()\n",
    "l2 = [i for i in l1]\n",
    "l1 = [i for i in l2]\n",
    "l2 = [round(i) for i in l1]\n",
    "df6 = pd.DataFrame(l2)\n",
    "\n",
    "my_list = [*range(4,935011,6)]\n",
    "df6['Id_1'] = my_list\n",
    "df6.rename(columns = {0 : 'Predicted_Results'}, inplace = True)\n",
    "\n",
    "result_fatalities = pd.concat([df4, df5, df6])\n",
    "result_fatalities.sort_values(by = ['Id_1'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Zg1TyfvZTHQG",
    "outputId": "ca21c143-5456-49b0-d15e-f8c26b95718a"
   },
   "outputs": [],
   "source": [
    "result_total = pd.concat([result_confirmed_cases, result_fatalities])\n",
    "result_total.sort_values(by = ['Id_1'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "yLU5x6FKTioo",
    "outputId": "53ead31f-55d6-43d7-a4e0-a2d5faa7a932"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ForecastId_Quantile</th>\n",
       "      <th>TargetValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_0.05</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_0.5</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_0.95</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2_0.05</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2_0.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935005</th>\n",
       "      <td>311669_0.5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935006</th>\n",
       "      <td>311669_0.95</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935007</th>\n",
       "      <td>311670_0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935008</th>\n",
       "      <td>311670_0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935009</th>\n",
       "      <td>311670_0.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935010 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ForecastId_Quantile  TargetValue\n",
       "0                   1_0.05          163\n",
       "1                    1_0.5          163\n",
       "2                   1_0.95          163\n",
       "3                   2_0.05            5\n",
       "4                    2_0.5            5\n",
       "...                    ...          ...\n",
       "935005          311669_0.5           31\n",
       "935006         311669_0.95           31\n",
       "935007         311670_0.05            0\n",
       "935008          311670_0.5            0\n",
       "935009         311670_0.95            0\n",
       "\n",
       "[935010 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission = pd.read_csv('./submission.csv')\n",
    "my_list = [*range(1,935011)]\n",
    "df_submission['Id'] = my_list \n",
    "final_result = pd.merge(df_submission,result_total, left_on = 'Id', right_on ='Id_1', how = 'inner')\n",
    "final_result.drop(['TargetValue','Id','Id_1'], axis =1, inplace = True)\n",
    "final_result.rename({'Predicted_Results' : 'TargetValue'}, axis = 1, inplace = True)\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "5rtEWSTTX4m_"
   },
   "outputs": [],
   "source": [
    "final_result.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "covid_19.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:covid19predict]",
   "language": "python",
   "name": "conda-env-covid19predict-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
